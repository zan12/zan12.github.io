
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html dir="ltr" lang="en-us"><head>

  
  <meta content="text/html; charset=UTF-8" http-equiv="content-type"><title>Aonan Zhang :: Apple</title>
  <style>
    h3 {
      font-size: 1.4em;
    }
  </style>
  <style>
  body {
    text-align: left;
    font-size: 1.1em;
    max-width: 720px;
    margin-left: auto;
    margin-right: auto;
    padding-left: 24px;
    padding-right: 24px;
    box-sizing: border-box;
  }
  </style>

<!-- Use Inter font for main text, matching thinkingmachines.ai -->
<style>
  body {
    font-family: 'Inter', Arial, Helvetica, sans-serif;
    font-weight: 400;
    letter-spacing: 0;
  }
</style>
  
  <meta content="Aonan Zhang" name="author">
  <link rel="preload" href="./personal/aonan.png" as="image">
  <style>
    .profile-photo {
      position: absolute;
      top: 32px;
      right: 48px;
      width: 110px;
      height: 110px;
      border-radius: 12px;
      object-fit: cover;
      box-shadow: 0 2px 8px rgba(0,0,0,0.08);
    }
    @media (max-width: 900px) {
      .profile-photo {
        position: static;
        display: block;
        margin: 0 auto 16px auto;
        float: none;
        right: auto;
        top: auto;
      }
    }
  </style>
  
  <meta content="homepage of aonan zhang at columbia university" name="description"></head><body style="background-color: rgb(247, 247, 247); color: rgb(0, 0, 0);" alink="#000099" link="#000099" vlink="#990099">

    <div style="position: relative; min-height: 30px;">
      <img src="./personal/aonan.png" alt="Aonan Zhang" class="profile-photo" style="position: absolute; top: 600; right: 0;">
    </div>

    
<table style="text-align: left; width: 680px; background-color: rgb(247, 247, 247); height: 210px;" border="0" cellpadding="2" cellspacing="2">

  <tbody>
    <tr>
      <td style="width: 100%; vertical-align: top; height: 50px;">
      <div style="margin-left: 0px;">
      <h3 style="margin-top: 6px; height: 5px;">Aonan Zhang 
        <a href="./personal/aonan_cv.pdf" target="_blank" style="vertical-align: top; margin-left: 4px; text-decoration: none;">
          <img src="./personal/CV.png" alt="CV" style="height: 28px; vertical-align: top;">
        </a>
        <a href="mailto:szyagn@gmail.com" target="_blank" style="vertical-align: top; margin-left: 4px; text-decoration: none;">
          <img src="./personal/email.png" alt="Email" style="height: 28px; vertical-align: top;">
        </a>
        <a href="https://scholar.google.com/citations?hl=zh-CN&user=Daa3WpMAAAAJ&view_op=list_works&sortby=pubdate" target="_blank" style="vertical-align: top; margin-left: 4px; text-decoration: none;">
          <img src="./personal/google_scholar.svg" alt="Google Scholar" style="height: 28px; vertical-align: top;">
        </a>
        <a href="https://www.linkedin.com/in/aonan-zhang-4208bb67" target="_blank" style="vertical-align: top; margin-left: 4px; text-decoration: none;">
          <img src="./personal/linkedin.png" alt="LinkedIn" style="height: 28px; vertical-align: top;">
        </a>
        <a href="https://x.com/Aonan12" target="_blank" style="vertical-align: top; margin-left: 4px; text-decoration: none;">
          <img src="./personal/x.jpeg" alt="X" style="height: 28px; vertical-align: top;">
        </a>
      </h3>
      
      <br>Research Scientist - Apple Foundation Model Team<br>
      </div>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; height: 65px;">

I build foundation models at Apple.<br>
My research focuses on <a href="https://arxiv.org/pdf/2403.09919" target="_blank">model efficiency</a> and <a href="https://arxiv.org/pdf/2403.09919" target="_blank">data generation</a>.<br><br>

Previously at ByteDance, I worked on <a href="https://arxiv.org/pdf/2110.13048" target="_blank">trillion-scale data subsampling</a>.<br>
At Google, I designed a <a href="https://arxiv.org/pdf/1810.04719">sequence model for speaker diarization</a> during my internship.<br>
I got my Ph.D from Columbia University, working with Prof. <a href="https://www.columbia.edu/~jwp2128/" target="_blank">John Paisley</a>.<br>
I finished my BS and MS at Tsinghua University, working with Prof. <a href="https://ml.cs.tsinghua.edu.cn/~jun/index.shtml">Jun Zhu</a>.<br><br>
      </td>
    </tr>
  </tbody>
</table>


<hr style="width: 100%; height: 2px; background-color: rgb(247, 247, 247);">
<h3 style="background-color: rgb(247, 247, 247);">Highlights</h3>

<span style="font-weight: bold;">[2025.9] Synthetic Bootstrapped Pretraining
</span>[<a href="https://www.arxiv.org/pdf/2509.15248">Arxiv</a>]<br>
Zitong Yang*, <b>Aonan Zhang*</b>, Hong Liu, Tatsu Hashimoto, Emmanuel Cand√®s, Chong Wang, Ruoming Pang
<br>
<span style="font-style: italic; color: #666; display: inline-block; margin-top: 4px;">
We generate synthetic data for pre-training by building a doc-to-doc mapping from scratch, without relying on a teacher model. This approach improves data efficiency on the scale of training a 3B model on 1T tokens.
</span>
<br><br>


<span style="font-weight: bold;">[2025.7] Apple Intelligence Foundation Language Models: Tech Report 2025
</span>[<a href="https://arxiv.org/pdf/2507.13575">Arxiv</a>][<a href="https://machinelearning.apple.com/research/apple-foundation-models-2025-updates">Official Blog Post</a>]<br>
Apple Foundation Model Team
<br>
<span style="font-style: italic; color: #666; display: inline-block; margin-top: 4px;">
I worked on math reasoning for Apple's latest on-device and server-side foundation language models.
</span>
<br><br>


<span style="font-weight: bold;">[2024.12] Recurrent Drafter for Fast Speculative
Decoding in Large Language Models
</span>[<a href="https://arxiv.org/pdf/2403.09919">Arxiv</a>][<a href="https://github.com/apple/ml-recurrent-drafter">Pytorch Code</a>][<a href="https://github.com/NVIDIA/TensorRT-LLM/blob/main/examples/redrafter/README.md">TensorRT LLM</a>]<br>
Yunfei Cheng, <b>Aonan Zhang</b>, Xuanyu Zhang, Chong Wang, Yi Wang
<br>
<span style="font-style: italic; color: #666; display: inline-block; margin-top: 4px;">
A simple and efficient speculative decoding algorithm that delivers significantly faster inference for large language models. The algorithm is readily deployable across multiple hardware platforms.
</span>
<br><br>


<span style="font-weight: bold;">[2024.7] Apple Intelligence Foundation Language Models
</span>[<a href="https://arxiv.org/pdf/2407.21075">Arxiv</a>][<a href="https://machinelearning.apple.com/research/introducing-apple-foundation-models">Official Blog Post</a>]<br>
Tom Gunter, Zirui Wang, Chong Wang, Ruoming Pang, Andy Narayanan, <b>Aonan Zhang</b>, et al.
<span style="font-style: italic; color: #666; display: inline-block; margin-top: 4px;">
I'm a core contributor to Apple's on-device foundation language models and scalable server models operating within Apple's Private Cloud Compute platform.
</span>
<br><br>


<span style="font-weight: bold;">[2024.4] MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training
</span>[<a href="https://arxiv.org/pdf/2403.09611">Arxiv</a>]<br>
Brandon McKinzie, Zhe Gan, et al.
<span style="font-style: italic; color: #666; display: inline-block; margin-top: 4px;">
 A family of multimodal models up to 30B parameters, that are SOTA in pre-training metrics and achieve competitive performance after supervised fine-tuning on a range of established multimodal benchmarks. I'm a contributor of the text backbone model.
</span>
<br><br>


<span style="font-weight: bold;">[2021.10] Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data
</span>[<a href="https://arxiv.org/pdf/2110.13048">Arxiv</a>]<br>
H. Wang, <b>A. Zhang</b>, C. Wang.
<span style="font-style: italic; color: #666; display: inline-block; margin-top: 4px;">
We designed a theoretically efficient data subsampling algorithm for negative-dominant datasets, and applied it to a click-through rate dataset containing over 0.3 trillion instances.
</span>
<br><br>


<span style="font-weight: bold;">[2019.2] Fully Supervised Speaker Diarization<br>
</span>[<a href="https://arxiv.org/pdf/1810.04719">Arxiv</a>][<a href="https://github.com/google/uis-rnn">Github</a>][<a href="https://www.youtube.com/watch?v=pGkqwRPzx9U">Video</a>][<a href="https://ai.googleblog.com/2018/11/accurate-online-speaker-diarization.html">Official Google AI Blog</a>]
<br>
<b>A. Zhang</b>, Q. Wang, Z. Zhu, J. Paisley, C. Wang
<span style="font-style: italic; color: #666; display: inline-block; margin-top: 4px;">
We introduce Unbounded Interleaved-State Recurrent Neural Networks (UIS-RNN), in which each speaker is modeled by a parameter-sharing RNN. This framework detects speaker changes on the fly, through anomalies in the RNN state transitions.
</span>
<br><br>

<!-- 
<b>A. Zhang</b>, Q. Wang, Z. Zhu, J. Paisley, C. Wang:
<br>

<span style="font-weight: bold;">Random Function Priors for Correlation Modeling<br>
</span><span style="font-style: italic;"></span><i>International Conference on Machine Learning (ICML)</i>, Long Beach, USA, 2019 [<a href="https://arxiv.org/abs/1905.03826">Arxiv</a>][<a href="https://github.com/AnzCol/prme">Github</a>]<br>
<br>

<b>A. Zhang</b>, Q. Wang, Z. Zhu, J. Paisley, C. Wang:
<br>

<span style="font-weight: bold;">Fully Supervised Speaker Diarization<br>
</span><span style="font-style: italic;"></span><i>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i>, Brighton, UK, 2019 [<a href="https://arxiv.org/abs/1810.04719">Arxiv</a>][<a href="https://github.com/google/uis-rnn">Github</a>][<a href="https://www.youtube.com/watch?v=pGkqwRPzx9U">Video</a>][<a href="https://ai.googleblog.com/2018/11/accurate-online-speaker-diarization.html">Official Google AI Blog</a>]<br>
Media reports: 
  <a href="https://venturebeat.com/2018/11/12/google-open-sources-ai-that-can-distinguish-between-voices-with-92-percent-accuracy/">VentureBeat</a>,
  <a href="https://siliconangle.com/2018/11/12/google-built-ai-model-can-accurately-distinguish-different-human-voices/">SiliconANGLE</a>, 
  <a href="https://www.infoq.com/news/2018/11/Google-AI-Voice">InfoQ</a>, 
  <a href="https://futurism.com/the-byte/google-ai-recognize-new-voices">futurism</a>, 
  <a href="https://www.cnbeta.com/articles/tech/787295.htm">cnBeta</a>, 
  <a href="https://tech.sina.com.cn/it/2018-11-13/doc-ihmutuea9658316.shtml">Sina Tech</a>, 
  <a href="https://www.ithome.com.tw/news/126984">iThome</a>, 
  <a href="http://www.chinaemail.com.cn/blog/content/9652/%E8%B0%B7%E6%AD%8C%E5%BC%80%E6%BA%90AI%E8%83%BD%E5%8C%BA%E5%88%86%E5%A3%B0%E9%9F%B3-%E5%87%86%E7%A1%AE%E7%8E%87%E8%BE%BE92%25.html">ChinaEmail</a>, 
  <a href="http://www.eepw.com.cn/article/201811/394377.htm">eepw</a>, 
  <a href="https://mp.weixin.qq.com/s/YOupCjU06JhRCZNCbMvAgQ">QbitAI</a>, 
  <a href="https://www.oschina.net/news/101780/fully-super-vised-speaker-diarization">oschina</a>.
<br><br>

<b>A. Zhang</b>, J. Paisley:
<br>

<span style="font-weight: bold;">Deep Bayesian Nonparametric Tracking<br>
</span><span style="font-style: italic;"></span><i>International Conference on Machine Learning (ICML)</i>, Stockholm, Sweden, 2018 [<a href="paper/zp18_icml.pdf">PDF</a>]<br>
<br>

S. Gultekin, <b>A. Zhang</b>, J. Paisley:
<br>

<span style="font-weight: bold;">Asymptotic Simulated Annealing for Variational Inference<br>
</span><span style="font-style: italic;"></span><i>IEEE Global Communications Conference (GLOBECOM)</i>, Abu Dhabi, UAE, 2018 [<a href="paper/gzp18_globecom.pdf">PDF</a>]<br>
<br>

<b>A. Zhang</b>, J. Paisley:
<br>

<span style="font-weight: bold;">Markov Latent Feature Models<br>
</span><span style="font-style: italic;"></span><i>International Conference on Machine Learning (ICML)</i>, New York, NY, 2016 [<a href="paper/zp16_icml.pdf">PDF</a>]<br>
<br>

<b>A. Zhang</b>, S. Gultekin, J. Paisley:
<br>

<span style="font-weight: bold;"> Stochastic Variational Inference for HDP-HMM<br>
</span><span style="font-style: italic;"></span><i>International Conference on Artificial Intelligence and Statistics (AISTATS)</i>, Cadiz, Spain, 2016 [<a href="paper/zgp16_aistats.pdf">PDF</a>]<br>
<br>

<b>A. Zhang</b>, J. Paisley:
<br>

<span style="font-weight: bold;">Markov Mixed Membership Models<br>
</span><span style="font-style: italic;"></span><i>International Conference on Machine Learning (ICML)</i>, Lille, France, 2015 [<a href="paper/zp15_icml.pdf">PDF</a>]<br>
<br>

<b>A. Zhang</b>, J. Zhu, B. Zhang:
<br>

<span style="font-weight: bold;">Max-margin Infinite Hidden Markov Models<br>
</span><span style="font-style: italic;"></span><i>International Conference on Machine Learning (ICML)</i>, Beijing, China, 2014 [<a href="paper/zzz14_icml.pdf">PDF</a>]<br>
<br>

F. Xia, N. Chen, J. Zhu, <b>A. Zhang</b>, X. Jin:
<br>

<span style="font-weight: bold;">Max-margin Latent Feature Relational Models for Entity-Attribute Networks<br>
</span><span style="font-style: italic;"></span><i>International Joint Conference on Neural Networks (IJCNN)</i>, Beijing, China, 2014 [<a href="paper/xczzj14_ijcnn.pdf">PDF</a>]<br>
<br>

<b>A. Zhang</b>, J. Zhu, B. Zhang:
<br>

<span style="font-weight: bold;">Sparse Relational Topic Models for Document Networks<br>
</span><span style="font-style: italic;"></span><i>European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD)</i>, Prague, Czech Republic, 2013. [<a href="paper/zzz13_ecml.pdf">PDF</a>]<br>
<br>

<b>A. Zhang</b>, J. Zhu, B. Zhang:
<br>

<span style="font-weight: bold;">Sparse Online Topic Models<br>
</span><span style="font-style: italic;"></span><i>International World Wide Web Conference (WWW)</i>, Rio de Janeiro, Brazil, 2013 [<a href="paper/zzz13_www.pdf">PDF</a>]<br>
<br> -->



<hr style="width: 100%; height: 2px; background-color: rgb(247, 247, 247);">
<pre style="background-color: rgb(247, 247, 247);">Last update: Oct 3rd, 2025</pre>

</body></html>
